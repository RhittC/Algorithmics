{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4799fa56",
   "metadata": {},
   "source": [
    "## VCE Algorithmics 3/4 - Unit 3 Area of Study 2: Algorithm Design Cheatsheet\n",
    "\n",
    "**Core Focus:**\n",
    "Designing algorithms using common design patterns and understanding graph algorithms. Emphasis is on *algorithmic thinking*, not coding.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "- **Algorithm**: A precise, step-by-step method for solving a problem.\n",
    "- **Algorithmic Design Patterns**: Standard approaches to structuring algorithms to solve classes of problems.\n",
    "- **Graph Algorithms**: Algorithms that operate on graph data structures to solve problems involving relationships, paths, and connectivity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Algorithm Design Patterns**\n",
    "\n",
    "- **Brute Force**: Try all possible solutions and select the best.\n",
    "    - *Pros*: Simple to implement.\n",
    "    - *Cons*: Often inefficient for large inputs.\n",
    "- **Greedy**: Make the locally optimal choice at each step, hoping for a global optimum.\n",
    "    - *Example*: Dijkstra’s algorithm for shortest paths.\n",
    "- **Divide and Conquer**: Split the problem into subproblems, solve them independently, and combine results.\n",
    "    - *Example*: Merge sort.\n",
    "- **Dynamic Programming**: Break problems into overlapping subproblems, solve each once, and store results for reuse.\n",
    "    - *Example*: Fibonacci sequence, shortest path in weighted graphs (Bellman-Ford).\n",
    "- **Backtracking**: Systematically search for a solution by trying partial solutions and abandoning them if they fail.\n",
    "    - *Example*: Sudoku solver, N-Queens problem.\n",
    "\n",
    "---\n",
    "\n",
    "### **Graph Algorithms**\n",
    "\n",
    "- **Graph Basics**\n",
    "    - **Graph**: Set of nodes (vertices) connected by edges.\n",
    "    - **Types**: Directed, undirected, weighted, unweighted, cyclic, acyclic.\n",
    "    - **Special Graphs**: Trees (connected, acyclic), DAGs (Directed Acyclic Graphs).\n",
    "- **Common Graph Algorithms**\n",
    "    - **Traversal**\n",
    "        - *Breadth-First Search (BFS)*: Explores neighbors level by level. Good for finding shortest path in unweighted graphs.\n",
    "        - *Depth-First Search (DFS)*: Explores as far as possible along each branch before backtracking. Good for cycle detection, path finding.\n",
    "    - **Shortest Path**\n",
    "        - *Dijkstra’s Algorithm*: Finds shortest paths from a source to all nodes in a weighted graph (no negative weights).\n",
    "        - *Bellman-Ford Algorithm*: Handles graphs with negative weights.\n",
    "    - **Minimum Spanning Tree**\n",
    "        - *Kruskal’s Algorithm*: Adds edges in order of increasing weight, avoiding cycles.\n",
    "        - *Prim’s Algorithm*: Grows the MST from a starting node by adding the cheapest edge.\n",
    "    - **Topological Sort**: Orders nodes in a DAG so that for every directed edge \\$ u \\to v \\$, \\$ u \\$ comes before \\$ v \\$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Algorithm Representation**\n",
    "\n",
    "- **Pseudocode**: Write algorithms in structured, language-agnostic steps.\n",
    "- **Flowcharts**: Visual diagrams showing the flow of control.\n",
    "- **IPO Charts**: Outline Input, Processing, Output for each algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "### **Design Process**\n",
    "\n",
    "1. **Understand the Problem**\n",
    "    - Identify the type of data and relationships involved.\n",
    "    - Recognize if the problem maps to a known pattern (e.g., shortest path, scheduling).\n",
    "2. **Select Data Structures**\n",
    "    - Use appropriate abstract data types (ADTs): arrays, lists, stacks, queues, graphs.\n",
    "3. **Choose a Design Pattern**\n",
    "    - Match the problem to a suitable algorithmic pattern.\n",
    "4. **Develop the Algorithm**\n",
    "    - Write clear pseudocode.\n",
    "    - Trace through with sample data to check correctness.\n",
    "5. **Evaluate**\n",
    "    - Consider efficiency (time/space complexity).\n",
    "    - Check for edge cases and correctness.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tips for SAC Preparation**\n",
    "\n",
    "- Practice writing pseudocode for each design pattern.\n",
    "- Be able to explain why a particular algorithm or pattern is suitable for a problem.\n",
    "- Know how to represent and traverse graphs (BFS, DFS).\n",
    "- Understand the pros and cons of each design pattern.\n",
    "- Be ready to model real-world problems as graphs or other ADTs.\n",
    "\n",
    "---\n",
    "\n",
    "### **Sample Glossary**\n",
    "\n",
    "| Term | Definition |\n",
    "| :-- | :-- |\n",
    "| Algorithm | Step-by-step procedure for solving a problem |\n",
    "| ADT (Abstract Data Type) | A model for data structures with defined operations |\n",
    "| Graph | Collection of nodes and edges representing relationships |\n",
    "| BFS | Explores graph level by level |\n",
    "| DFS | Explores graph by going deep before backtracking |\n",
    "| Greedy Algorithm | Makes the best choice at each step |\n",
    "| Dynamic Programming | Solves overlapping subproblems and stores results |\n",
    "| Backtracking | Tries solutions and abandons unsuccessful paths |\n",
    "| Topological Sort | Orders nodes in a DAG |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam/Assessment Style Reminders**\n",
    "\n",
    "- Clearly explain your reasoning and choice of algorithm.\n",
    "- Use diagrams where helpful (especially for graphs).\n",
    "- Justify data structure and design pattern choices.\n",
    "- Show step-by-step execution for algorithms (especially traversals).\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "For Unit 3 Area of Study 2, focus on understanding and applying algorithm design patterns, especially in the context of graph problems. Practice representing problems, selecting appropriate algorithms, and justifying your choices in clear, structured pseudocode or diagrams.\n",
    "\n",
    "---\n",
    "\n",
    "### Proofs of Correctness for Key Algorithms\n",
    "\n",
    "#### **Dijkstra's Algorithm**\n",
    "\n",
    "**Goal**: Find shortest paths from a source node in a weighted graph with non-negative edges.\n",
    "**Proof by Induction**:\n",
    "\n",
    "- **Base Case**: Initially, only the source node \\$ s \\$ is visited (\\$ R = \\{s\\} \\$), and \\$ d(s) = 0 \\$, which is correct.\n",
    "- **Inductive Step**: Assume all nodes in \\$ R \\$ have correct shortest distances. When adding a new node \\$ u \\$ (with minimal \\$ d(u) \\$), its shortest path must pass through nodes in \\$ R \\$. Since all edge weights are non-negative, \\$ d(u) \\$ cannot be improved later, ensuring correctness.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Bellman-Ford Algorithm**\n",
    "\n",
    "**Goal**: Find shortest paths in graphs with possible negative weights (no negative cycles).\n",
    "**Correctness**:\n",
    "\n",
    "1. After \\$ |V|-1 \\$ relaxations, all shortest paths (with ≤ \\$ |V|-1 \\$ edges) are found. By the triangle inequality, no further improvements are possible in absence of negative cycles.\n",
    "2. **Negative Cycle Detection**: If a distance can still be improved after \\$ |V|-1 \\$ steps, a negative cycle exists. The algorithm returns FALSE in this case.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Kruskal's Algorithm**\n",
    "\n",
    "**Goal**: Construct a minimum spanning tree (MST).\n",
    "**Proof**:\n",
    "\n",
    "- **Spanning Tree**:\n",
    "    - **Acyclic**: Edges are added only if they don’t form cycles (union-find structure).\n",
    "    - **Connected**: If disconnected, an edge connecting two components would exist and be added.\n",
    "- **Minimality**: Assume a cheaper MST \\$ T \\$. Let \\$ e \\$ be the first edge in Kruskal’s output not in \\$ T \\$. Adding \\$ e \\$ to \\$ T \\$ creates a cycle; swapping \\$ e \\$ with a heavier edge \\$ f \\$ in the cycle yields a cheaper MST, contradicting \\$ T \\$’s minimality.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Prim's Algorithm**\n",
    "\n",
    "**Goal**: Construct an MST by growing a tree from a starting node.\n",
    "**Proof**:\n",
    "\n",
    "- At each step, the algorithm adds the cheapest edge connecting the tree to a new node (cut property). This ensures all edges in the tree are part of an MST.\n",
    "- If the output \\$ Y \\$ were not minimal, swapping edges between \\$ Y \\$ and a hypothetical cheaper MST \\$ Y' \\$ would yield a contradiction, as shown via edge substitution.\n",
    "\n",
    "---\n",
    "\n",
    "#### **BFS (Shortest Path in Unweighted Graphs)**\n",
    "\n",
    "**Goal**: Find shortest paths in unweighted graphs.\n",
    "**Proof**:\n",
    "\n",
    "- Explores nodes in levels, ensuring the first visit to a node records the shortest path (no shorter path exists via unvisited nodes).\n",
    "\n",
    "---\n",
    "\n",
    "#### **DFS (Connectivity/Cycle Detection)**\n",
    "\n",
    "**Goal**: Traverse all nodes or detect cycles.\n",
    "**Proof**:\n",
    "\n",
    "- **Cycle Detection**: A back edge (visiting an already visited ancestor) indicates a cycle.\n",
    "- **Connectivity**: Explores all reachable nodes from a starting point.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "Each algorithm’s correctness hinges on invariants maintained during execution (e.g., Dijkstra’s greedy choice, Bellman-Ford’s relaxation limits, Kruskal/Prim’s MST properties). Mastery of these proofs requires understanding their inductive logic and contradiction arguments.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pseudocode for Key Algorithms (VCE Algorithmics SAC-Ready)**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Dijkstra’s Algorithm (Shortest Path in Weighted Graphs)**\n",
    "\n",
    "**Assumption**: No negative edge weights.\n",
    "\n",
    "```plaintext  \n",
    "function DIJKSTRA(graph, source):  \n",
    "    Initialize distances: distances[v] = ∞ for all nodes v  \n",
    "    distances[source] = 0  \n",
    "    priority_queue = {(source, 0)}  \n",
    "    visited = empty set  \n",
    "\n",
    "    while priority_queue is not empty:  \n",
    "        u = extract node with minimum distance from priority_queue  \n",
    "        if u is in visited:  \n",
    "            continue  \n",
    "        add u to visited  \n",
    "        for each neighbor v of u:  \n",
    "            if distances[v] > distances[u] + weight(u, v):  \n",
    "                distances[v] = distances[u] + weight(u, v)  \n",
    "                add (v, distances[v]) to priority_queue  \n",
    "    return distances  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Uses a priority queue to always select the next closest node.\n",
    "- Fails if negative edges exist (use Bellman-Ford instead).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Bellman-Ford Algorithm (Handles Negative Weights)**\n",
    "\n",
    "```plaintext  \n",
    "function BELLMAN_FORD(graph, source):  \n",
    "    Initialize distances: distances[v] = ∞ for all nodes v  \n",
    "    distances[source] = 0  \n",
    "\n",
    "    repeat |V| - 1 times:  \n",
    "        for each edge (u, v) with weight w:  \n",
    "            if distances[v] > distances[u] + w:  \n",
    "                distances[v] = distances[u] + w  \n",
    "\n",
    "    // Check for negative cycles  \n",
    "    for each edge (u, v) with weight w:  \n",
    "        if distances[v] > distances[u] + w:  \n",
    "            return \"Negative cycle detected\"  \n",
    "    return distances  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Relaxes all edges \\$ |V|-1 \\$ times.\n",
    "- Detects negative cycles in the final pass.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Kruskal’s Algorithm (Minimum Spanning Tree)**\n",
    "\n",
    "```plaintext  \n",
    "function KRUSKAL(graph):  \n",
    "    sort all edges in ascending order of weight  \n",
    "    mst = empty set  \n",
    "    parent = array where parent[v] = v for all nodes v  \n",
    "\n",
    "    for each edge (u, v, w) in sorted edges:  \n",
    "        if FIND(u, parent) ≠ FIND(v, parent):  \n",
    "            add (u, v, w) to mst  \n",
    "            UNION(u, v, parent)  \n",
    "\n",
    "    return mst  \n",
    "\n",
    "// Helper functions for Union-Find  \n",
    "function FIND(node, parent):  \n",
    "    while parent[node] ≠ node:  \n",
    "        node = parent[node]  \n",
    "    return node  \n",
    "\n",
    "function UNION(u, v, parent):  \n",
    "    root_u = FIND(u, parent)  \n",
    "    root_v = FIND(v, parent)  \n",
    "    parent[root_v] = root_u  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Uses Union-Find to avoid cycles.\n",
    "- Greedily adds the smallest edge that connects new components.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Prim’s Algorithm (MST from a Starting Node)**\n",
    "\n",
    "```plaintext  \n",
    "function PRIM(graph, start):  \n",
    "    Initialize key[v] = ∞ for all nodes v  \n",
    "    key[start] = 0  \n",
    "    priority_queue = {(start, 0)}  \n",
    "    parent = array where parent[v] = null for all v  \n",
    "    in_mst = empty set  \n",
    "\n",
    "    while priority_queue is not empty:  \n",
    "        u = extract node with minimum key from queue  \n",
    "        add u to in_mst  \n",
    "        for each neighbor v of u:  \n",
    "            if v not in in_mst and weight(u, v) < key[v]:  \n",
    "                key[v] = weight(u, v)  \n",
    "                parent[v] = u  \n",
    "                add (v, key[v]) to priority_queue  \n",
    "    return parent  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Similar to Dijkstra but tracks edge weights instead of total distance.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. BFS (Shortest Path in Unweighted Graphs)**\n",
    "\n",
    "```plaintext  \n",
    "function BFS(graph, source):  \n",
    "    Initialize distances: dist[v] = -1 for all nodes v  \n",
    "    dist[source] = 0  \n",
    "    queue = empty queue  \n",
    "    enqueue source into queue  \n",
    "\n",
    "    while queue is not empty:  \n",
    "        u = dequeue from queue  \n",
    "        for each neighbor v of u:  \n",
    "            if dist[v] == -1:  \n",
    "                dist[v] = dist[u] + 1  \n",
    "                enqueue v into queue  \n",
    "    return dist  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Uses a queue to explore nodes level by level.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. DFS (Cycle Detection/Connectivity)**\n",
    "\n",
    "```plaintext  \n",
    "function DFS(graph, start):  \n",
    "    visited = empty set  \n",
    "    stack = empty stack  \n",
    "    push start onto stack  \n",
    "\n",
    "    while stack is not empty:  \n",
    "        u = pop from stack  \n",
    "        if u not in visited:  \n",
    "            add u to visited  \n",
    "            for each neighbor v of u:  \n",
    "                if v not in visited:  \n",
    "                    push v onto stack  \n",
    "    return visited  \n",
    "```\n",
    "\n",
    "**Cycle Detection**: Track recursion stack or use a \"parent\" node to avoid false back edges.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Topological Sort (for DAGs)**\n",
    "\n",
    "```plaintext  \n",
    "function TOPO_SORT(graph):  \n",
    "    visited = empty set  \n",
    "    stack = empty stack  \n",
    "\n",
    "    for each node u in graph:  \n",
    "        if u not in visited:  \n",
    "            DFS_VISIT(u, visited, stack)  \n",
    "\n",
    "    return stack (reversed order)  \n",
    "\n",
    "function DFS_VISIT(u, visited, stack):  \n",
    "    add u to visited  \n",
    "    for each neighbor v of u:  \n",
    "        if v not in visited:  \n",
    "            DFS_VISIT(v, visited, stack)  \n",
    "    push u onto stack  \n",
    "```\n",
    "\n",
    "**Key Points**:\n",
    "\n",
    "- Uses DFS to process nodes in reverse post-order.\n",
    "\n",
    "---\n",
    "\n",
    "### **Pseudocode Tips for SACs**\n",
    "\n",
    "1. **Clarity > Syntax**: Focus on logic, not language-specific details.\n",
    "2. **Use Descriptive Names**: e.g., `distances`, `parent`, `priority_queue`.\n",
    "3. **Comment Sparingly**: Only if it clarifies non-obvious steps.\n",
    "4. **Align with Design Patterns**:\n",
    "    - Greedy: Dijkstra, Prim, Kruskal.\n",
    "    - Dynamic Programming: Bellman-Ford.\n",
    "\n",
    "**Common Mistakes to Avoid**:\n",
    "\n",
    "- Forgetting to check for cycles in Kruskal’s.\n",
    "- Missing the negative cycle check in Bellman-Ford.\n",
    "- Using BFS for weighted graphs.\n",
    "\n",
    "Good luck! 🚀\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
