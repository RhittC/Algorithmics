{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9456760,"sourceType":"datasetVersion","datasetId":5748795}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 3.1 Solving Problems Breakout - Team X Zuse\nDaniel L., Edward M., Rhitt C., Sai C.<br>","metadata":{"id":"KkqYi-bfp2Vo"}},{"cell_type":"markdown","source":"With your team answer the following problems documenting your algorithms and responses in the shared file for your team.\n\n\n\n## Problem 1 - Searching\nHow many algorithms are there for solving the problem: Guess my number in a given interval say $[1,100]$?<br><br>\n\n### Response:\nAssumption: You are satisfied with an output equal to your number $x\\in\\mathbb{R}$ to a given number of decimal places.<br>Without this assumption, there are infinite candidates and so if $x$ is a non-terminatinating decimal or in a few other algorithm-specific cases, it is impossible for an algorithm to terminate (bad behaviour).<br><br>\n\nAssumption: I can always compare my guesses with yours using $<$ and $=$ bolean operations<br><br>\n\nBinary Search, Sequential Search, Random Guessing, etc.<br>\nTheoretically $\\infty$<br>\n\n\n\n- The process for searching algorithms is as follows:\n> 1. Make an estimate in interval\n> 2. Compare that estimate with the true value\n> 3. Use that information, and the well-ordering of the real numbers, to restrict interval(more on this below)\n> 4. Repeat until estimate must be $x$\n\n\\begin{gather}\n\\boxed{1,2,3,4,5,6,7,8}\\\\\n\\downarrow\\\\\n1,2,\\boxed{3,4,5,6,7,8}\\\\\n\\downarrow\\\\\n1,2,\\boxed{3,4,5,6,7},8\\\\\n\\downarrow\\\\\n1,2,3,\\boxed{4,5,6,7},8\\\\\n\\downarrow\\\\\n1,2,3,\\boxed{4,5},6,7,8\\\\\n\\downarrow\\\\\n1,2,3,\\boxed{4},5,6,7,8\n\\end{gather}\n\n$\\qquad$Because there are infinite procedures one can take to make estimates (no one's stopping you from \"estimating\" a value correlating to the $100th$ sig. fig. of the velocity of your dog in $ms^{-1}$ at a given time, for instance), there are technically infinite ways to implement an algorithm, all with different runtimes depending on the inputs.\n<br><br>\n- However, without additional information, Binary Search is guaranteed to use the estimate that gives the most optimal average-time-complexity. This is because it exploits the symmetry of the invterval. It is clear that neither half of the interval should be preferenced if avoidable, as the true value preferences the other half in the equally likely worst case. So the estimate MUST restrict the interval directly in half every iteration if possible. That is, it must be the arithmetic mean of the bounds (potentially then rounded to a given precision if required e.g. $50.5\\approx51$. This is a trivial extension, so not considering this). This is the essence of Binary Search.\n\n\\begin{gather}\n\\boxed{1,2,3,4,5,6,7,8}\\\\\n\\downarrow\\\\\n\\boxed{1,2,3,4},5,6,7,8\\\\\n\\downarrow\\\\\n1,2,\\boxed{3,4},5,6,7,8\\\\\n\\downarrow\\\\\n1,2,3,\\boxed{4},5,6,7,8\n\\end{gather}\n\n<br><br>\nBinary Search Time Complexity Analysis:<br>\nFor simplicity, only considering intervals with $2^m$ candidate elements, such that $m\\in\\mathbb{N}$, and lower bound of $1$. All other finite cases are trivial extensions of this case.<br>\nLet the interval be $[1, n]$. The problem size is then $n$.<br>\nEvery iteration of Binary Search reduces the problem size in half. Therefore,\n$$n\\rightarrow\\frac{n}{2}\\rightarrow\\frac{n}{4}\\rightarrow\\cdots\\rightarrow\\frac{n}{2^i}$$\nwhere $i$ is the number of reductions done, i.e. the number of iterations.<br>\nThe algorithm terminates when the problem size reaches $1$, when it can return the solution $x$ with certainty.<br>\nThe following analysis can now be conducted:\n\n$$\\begin{aligned}\n\\frac{n}{2^i} &= 1\\\\\nn &= 2^i\\\\\ni &= \\log_2{n}\n\\end{aligned}$$\n\nEvery iteration takes a constant number of operations (independent of problem size). Finally,\n\n\\begin{aligned}\nT(n)&=c\\cdot\\log_2{n}\\\\\n\\therefore\\;T(n)&=\\boxed{\\Theta(\\log(n))}\n\\end{aligned}\n\nWhy is this result not linear? How is it possible to determine your number for CERTAIN without explicitly checking every candidate? That is because the $<$ operator is transitive for all real numbers. That is, if you know $a < b$ and $b < c$, it follows that $a < c$. Binary Search exploits this property to eliminate many candidates implicitly, resulting in this blazingly fast complexity.","metadata":{"id":"v3DYtj_WqMOB"}},{"cell_type":"markdown","source":"### Binary Search","metadata":{"id":"Hdo_ahYUJOPo"}},{"cell_type":"markdown","source":"#### Pseudocode\nInput\n\n---\n- $a, b \\in \\mathbb{R}$ such that $a < b$, passed by value (write access)<br> representing bounds of $x \\in [a, b]$\n\n- lambda function $l(q)$<br>representing whether $x < q$\n- $p\\in\\mathbb{N}\\cup\\{0\\}$<br> representing number of decimal places with which to return $x$\n\nOutput\n\n---\n- $x$ to $p$ decimal places\n\nAlgorithm\n\n---\nwhile ($a$ to $p$ d.p. $\\neq b$ to $p$ d.p.) do:<br>\n$\\qquad$ $\\mu\\leftarrow\\frac{b-a}{2}$<br>\n$\\qquad$ if $l(\\mu)$ then:<br>\n$\\qquad\\qquad$ $b\\leftarrow\\mu$<br>\n$\\qquad$ else then:<br>\n$\\qquad$$\\qquad$ $a\\leftarrow\\mu$<br>\n$\\qquad$ end if<br>\nend while<br>\nreturn $a$ to $p$ d.p.\n","metadata":{"id":"URQ0ccLuJtkC"}},{"cell_type":"markdown","source":"#### Python","metadata":{"id":"wTxM4j_PW2qv"}},{"cell_type":"code","source":"import time\n\ndef binary(a, b, x_less_than, precision):\n  while round(a, precision) != round(b, precision):\n    mean = (b+a)/2\n    if x_less_than(mean):\n      b = mean\n    else:\n      a = mean\n  return round(a, precision)\n\na = float(input(\"lower bound a: \"))\nb = float(input(\"upper bound b: \"))\nprecision = int(input(\"number of decimal places: \"))\nx = float(input(\"x: \"))\nstart = time.time()\nprint(f\"found x = {binary(a, b, lambda inputted : x < inputted, precision)}\",\n      f\"in {time.time() - start:.20E} secs\")","metadata":{"id":"WvKIaB6YW6Aj","outputId":"8e43c742-68b7-4177-ebbb-22f10cd7144c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Problem 2 - Square Rooting\nFind $\\sqrt{S}$ without a calculator<br><br>\n### Response:\nAssumption: $S \\in \\mathbb{R}^{+}$\n\n- The naive solution is Binary Search with a lower bound of $0$ and upper bound of $S$. This algorithm\n> 1. Finds the average of the two bounds, $x$\n> 2. Squares $x$ and compares with $S$\n> 3. Selects $x$ as the new upper bound if $x^2 < S$\n> 4. Selects $x$ as the new lower bound if $x^2 > S$\n> 5. Iterates until the bounds are within the inputted precision, in which case it returns $x$ to the given precision\n<br>\n\nThis takes $O(\\log(n))$ time, where $n$ is the number of candidates in the range accounting for precision.\n- A more optimal approach is Heron's Method (commonly conflated with the formula for the area of a triangle from its side lengths), which is actually just a special case of the famous Newton's Method. The idea is to exploit the following:\n$$\na = \\sqrt{S}\\\\\na^2 = S\n$$\n\n$$\\tag{1}a^2 - S = 0$$\n<br>\nDefine $f:\\mathbb{R}^+\\rightarrow\\mathbb{R},f(x)=x^2-S$<br>\nThe solution $x=a$ to the problem satisfies $f(a)=0$ due to $(1)$<br>\nGiven an initial estimate $x_1$ sufficiently close to $a$, the $x$-coordinate of the $x$-intercept of the tangent line at $x=x_1$ gives a much closer estimate for $a$. So the algorithm essentially uses $f'(x)$ to obtain a good linear approximation $l(x)$ for $f(x)$ near $x=x_n$. The root of a linear function is easy to determine, and this becomes the new $x_{n+1}$. The algorithm then iterates until the given precision is reached.\n\n---\n$$\\begin{aligned}\ny-y_n&=m(x-x_n)\\\\\nl(x)-f(x_n)&=f'(x_n)(x-x_n)\\\\\nx-x_n&=\\frac{l(x)-f(x_n)}{f'(x_n)}\\\\\nx&=x_n+\\frac{l(x)-f(x_n)}{f'(x_n)}\\\\\n\\end{aligned}$$\n\n---\n$$\\begin{aligned}\n\\therefore x_{n+1}&=x_n+\\frac{0-(x_n^2-S)}{2x_n-0}\\\\\n&=\\frac{2x_n^2}{2x_n}+\\frac{-x^2+S}{2x_n}\\\\\n&= \\boxed{\\frac{1}{2}\\left(x_n+\\frac{S}{x_n}\\right)}\n\\end{aligned}$$\nNote that this assumes $a\\neq 0$<br>\nThis is the recurrence relation used in Heron's method<br>\nThis evidently requires much less iterations than Binary Search, as it utilises additional information to restrict the interval, and the operations performed by each iteration do not change, and so the time complexity is expected to be much faster.<br>\nBelow is a visualisation:","metadata":{"id":"90FPh1FDrHXT"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x, S):\n  return x**2 - S\n\ndef dfdx(x, S):\n  return 2*x\n\ndef l(x, x_n, S):\n  return dfdx(x_n, S) * (x-x_n) + f(x_n, S)\n\ndef x_next(x, x_n, S):\n  return (x_n + (S / x_n)) / 2\n\nS = 31\nx = np.linspace(-1, S//2, num=1000)\nx_n = S//3\nn = 3\n\nplt.figure(num=0, dpi=120)\nfig = plt.figure()\n\n# f(x)\nax = fig.add_subplot(111)\nax.set_title(\"Heron's Method Visualised\")\nax.plot(x, f(x, S), linewidth=3)\nax.text(x[-1] + 0.3, f(x[-1], S), f\"$f(x)=x^2-{S}$\", color='C0')\n\n# tangent at x=a for reference\n#ax.plot(x, l(x, np.sqrt(S), S), color='C0')\n#ax.plot(np.sqrt(S), 0, 'C0o')\n#ax.text(x[-1] + 0.3, l(x[-1], np.sqrt(S), S), f\"$l_a(x)$\", color='C0')\n\n# tangents from herons\nfor i in range(1, n+1):\n  ax.plot(x, l(x, x_n, S))\n  #ax.text(x[-1] + 0.3, l(x[-1], x_n, S), f\"$l_{i}(x)$\", color='C'+str(i))\n\n  ax.plot(x_n, l(x_n, x_n, S), 'C'+str(i)+'o')\n\n  x_n = x_next(x, x_n, S)\n  ax.plot(x_n, 0, 'C'+str(i)+'o')\n  ax.axvline(x = x_n, color='C'+str(i), linestyle=\"dotted\")\n\n#axes\nax.spines['left'].set_position('zero')\nax.spines['right'].set_color('none')\nax.spines['bottom'].set_position('zero')\nax.spines['top'].set_color('none')\n\n# remove the ticks from the top and right edges\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')","metadata":{"id":"ZTkW_vfOzMbV","outputId":"044a821f-21c9-4469-f09d-a1687b18f93e","trusted":true,"execution":{"execution_failed":"2025-02-10T04:49:22.036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pseudocode\nPreliminary Calculations and Discussion:\n\n$p$ d.p. $\\implies$ terminate when $x_n$ rounds to $a$ \\begin{gather}\\implies a-m \\le x_n < a+m\\\\\\implies x_n-m<a\\le x_n+m\\\\\\implies (x_n-m)^2<a^2\\le(x_n+m)^2\\end{gather} where the margin of error $m=5\\cdot10^{-p-1}$ and $a$ is to $p$ d.p.<br>\nBut $a$ itself is rounded, so to account for the slight discrepancy between $a^2$ and $S$, restrict the margin of error further\n$$\n(x_n-m)^2\\le S\\le(x_n+m)^2, m=5\\cdot10^{-p-2}\n$$\n<br><br>\n\nA very good initial estimate can be obtained by rounding $S$ to the nearest even power of $2$, which is then easy to root.<br><br>\n\n\nInput\n\n---\n- $S\\in\\mathbb{R}^+$<br>representing the value to be square rooted\n- $p\\in\\mathbb{N}\\cup\\{0\\}$<br>representing the number of decimal places required\n\nOutput\n\n---\n- $\\sqrt{S}$ to $p$ d.p\n\nAlgorithm\n\n---\n\\begin{align}\n&x\\leftarrow2^{\\lfloor\\frac{\\log_2(S)}{2}+\\frac{1}{2}\\rfloor}\\\\\n&m\\leftarrow5\\cdot10^{-p-2}\\\\\n&while\\;S\\notin[(x-m)^2,\\;(x+m)^2]\\;do:\\\\\n&\\qquad x\\leftarrow\\frac{1}{2}\\left(x+\\frac{S}{x}\\right)\\\\\n&end\\;while\\\\\n&return\\;x\n\\end{align}","metadata":{"id":"O1PF4w4WHoce"}},{"cell_type":"markdown","source":"### Python","metadata":{"id":"loZPgHYV7iHc"}},{"cell_type":"code","source":"import numpy as np\nimport time\n\n\ndef binary(S, precision):\n  a = 0\n  b = S\n  m = 5*(10**(-precision-2))\n  i = 0\n  mean = S/2\n  while not ((mean-m)**2 <= S <= (mean+m)**2):\n    i +=1\n\n    mean = (b+a)/2\n    if S < mean**2:\n      b = mean\n    else:\n      a = mean\n  print(f\"Number of iterations: {i}\")\n  return round(mean, precision)\n\n\n\ndef herons(S, precision):\n  x = 2**round(np.log2(S)/2)\n  m = 5*(10**(-precision-2))\n  i = 0\n  while not ((x-m)**2 <= S <= (x+m)**2):\n    i += 1\n    x = (x + S/x)/2\n  #return x\n  print(f\"Number of iterations: {i}\")\n  return round(x, precision)\n\nS = float(input(\"S: \"))\nprecision = int(input(\"Precision: \"))\nprint()\n\nstart = time.time()\nprint(\"Square root of S(naive):\")\nprint(f\"Answer: {binary(S, precision)}\")\nprint(f\"Found in {time.time() - start:.20E} secs\")\nprint()\n\nstart = time.time()\nprint(f\"Square root of S (herons):\")\nprint(f\"Answer: {herons(S, precision)}\")\nprint(f\"Found in {time.time() - start:.20E} secs\")","metadata":{"id":"cd_aalcXbSSE","outputId":"51f8e945-6f47-40af-8a79-a5d95a0bf15e","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T05:52:29.365521Z","iopub.execute_input":"2025-02-09T05:52:29.365908Z","iopub.status.idle":"2025-02-09T05:52:36.258697Z","shell.execute_reply.started":"2025-02-09T05:52:29.365875Z","shell.execute_reply":"2025-02-09T05:52:36.257243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Interesting Observations\nThe \"naive\" Binary Search algorithm does not seem to have consistent difference to Heron's Method in terms of speed for almost all inputs tested. In terms of iterations though, Heron requires significantly less.<br><br>\nThis is likely because division by $x$ is internally calculated by repeated subtraction, thus introducing unwanted $x$ dependency, meaning subsequent iterations require significantly more time to complete. However, further investigation is needed to make a conclusive statement. It is still possible that this unexpected behaviour is merely machine or implementation specific.","metadata":{"id":"232xBfzz7gBj"}},{"cell_type":"markdown","source":"## Problem 3 - Wordladder","metadata":{"id":"ebnwtBiqfegE"}},{"cell_type":"code","source":"import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom queue import PriorityQueue\n\n\ndef show(G, levels, spacing, path_nodes, path_edges):\n    pos = {}\n    maxl = max(levels.values())\n    xdict = {level: list(levels.values()).count(level) for level in range(maxl + 1)}\n\n    for level in range(maxl+1):\n        words = [word for word, i in levels.items() if i==level]\n        offset = (xdict[level]-1)/2\n        for i, word in enumerate(words):\n            pos[word] = ((i-offset)*spacing, maxl-level)\n\n    plt.figure(figsize=(spacing*3,spacing))\n    nx.draw(G, pos, with_labels=True, node_color='lightblue',\n            node_size=300, font_size=6, edge_color='gray')\n    nx.draw_networkx_nodes(G, pos, nodelist=path_nodes, node_color=\"pink\", node_size=300)\n    nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color=\"pink\")\n    \n    plt.show()\n\n\ndef priority(word, goal):\n    count = len(word)\n    for i in range(len(word)):\n        if word[i] == goal[i]:\n            count -= 1\n    return count\n\n\ndef unseen_neighbours(word, goal):\n    neighbours = {}       \n    for i in range(len(word)):\n        for c in range(ord('a'), ord('z')+1):\n            candidate = word[:i] + chr(c) + word[i+1:]\n            if candidate in unseen_words:\n                if goal[i] == chr(c):\n                    neighbours[candidate] = -1   # using letters different to goal as heuristic\n                elif word[i] == goal[i]:         # i.e replaced word[i] in correct place with the bogus c\n                    neighbours[candidate] = 1\n                else:\n                    neighbours[candidate] = 0\n    return neighbours\n\n\ndef bestfs(initial, goal):\n    G = nx.DiGraph()\n    G.add_node(initial)\n    \n    q = PriorityQueue()\n    q.put((priority(initial, goal), initial, 0))\n    predecessors = {initial: None}\n    levels = {initial: 0}\n    \n    while not q.empty():\n        p, current, level = q.get()\n        #print(p, current)\n\n        # populate q and housekeeping\n        neighs = unseen_neighbours(current, goal)\n        for neigh in neighs.keys():\n            # vital\n            prior = p + neighs[neigh]\n            unseen_words.discard(neigh)\n\n            # for visualisation purposes\n            predecessors[neigh] = current\n            G.add_edge(current, neigh)\n            levels[neigh] = level+1\n\n            if prior == 0:\n                return G, predecessors, levels\n\n            q.put((p+neighs[neigh], neigh, level+1))\n\n    return None, None, None\n\n\npath = \"/kaggle/input/dictionary-of-english-words-and-definitions/dict.csv\"\nunseen_words = set(pd.read_csv(path)[\"word\"])    # sets are hashed, so O(1) lookup   # global variables as too large\n\ninitial = input(\"Initial Word: \")\nunseen_words.remove(initial)\ngoal = input(\"Goal Word: \")\n\nG, predecessors, levels = bestfs(initial, goal)\nif G is None:\n    print(\"No Solution\")\nelse:\n    # find path\n    path_nodes, path_edges = [], []\n    current = goal\n    while not current is None:\n        pred = predecessors[current]\n        path_nodes.append(current)\n\n        if not pred is None:\n            path_edges.append((pred, current))\n        current = pred\n    \n    show(G, levels, len(initial), path_nodes, path_edges)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T03:45:49.001458Z","iopub.execute_input":"2025-02-10T03:45:49.001747Z","iopub.status.idle":"2025-02-10T03:45:53.440105Z","shell.execute_reply.started":"2025-02-10T03:45:49.001724Z","shell.execute_reply":"2025-02-10T03:45:53.438646Z"}},"outputs":[],"execution_count":null}]}